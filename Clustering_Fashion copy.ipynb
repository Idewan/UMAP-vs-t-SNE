{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-hLt9Wqsi78u"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import hdbscan\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import fetch_openml\n",
    "import sklearn.datasets as dt\n",
    "import scipy\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.utils import resample\n",
    "from tensorflow.keras.datasets.fashion_mnist import load_data\n",
    "\n",
    "#Import all the algorithms\n",
    "from umap import UMAP\n",
    "import openTSNE\n",
    "from openTSNE import TSNE as OpenTSNE\n",
    "from openTSNE import affinity, initialization, TSNEEmbedding\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZoElb-3YCDNQ"
   },
   "outputs": [],
   "source": [
    "def embedding_metrics(X, Z, classes, knn=10, knn_classes=10, subsetsize=1000):\n",
    "    intersections_knn = 0\n",
    "    intersections_knc = 0\n",
    "\n",
    "    ## KNN ##\n",
    "    #Compute the set of KNN on the true and embedded data\n",
    "    neighbor_true_data_knn = NearestNeighbors(n_neighbors=knn).fit(X)\n",
    "    set_true_knn = set(neighbor_true_data_knn.kneighbors(return_distance=False))\n",
    "    neighbor_embed_data_knn = NearestNeighbors(n_neighbors=knn).fit(Z)\n",
    "    set_embed_knn = set(neighbor_embed_data_knn.kneighbors(return_distance=False))\n",
    "\n",
    "    #Compute the intersections between true and embedding\n",
    "    for i in range(X.shape[0]):\n",
    "        intersections_knn += len(set_true_knn[i] & set_embed_knn[i])\n",
    "    KNN = intersections_knn / (X.shape[0] * knn)\n",
    "\n",
    "    ## KNC ##\n",
    "    #Build the class means\n",
    "    cl, cl_inv = np.unique(classes, return_inverse=True)\n",
    "    C = cl.size\n",
    "    mu1 = np.zeros((C, X.shape[1]))\n",
    "    mu2 = np.zeros((C, Z.shape[1]))\n",
    "    for c in range(C):\n",
    "        mu1[c,:] = np.mean(X.iloc[cl_inv==c,:], axis=0)\n",
    "        mu2[c,:] = np.mean(Z[cl_inv==c,:], axis=0)\n",
    "    \n",
    "    #KNN on the class means\n",
    "    neighbor_true_data_knc = NearestNeighbors(n_neighbors=knn_classes).fit(mu1)\n",
    "    set_true_knc = neighbor_true_data_knc.kneighbors(return_distance=False)\n",
    "    neighbor_embed_data_knc = NearestNeighbors(n_neighbors=knn_classes).fit(mu2)\n",
    "    set_embed_knc = neighbor_embed_data_knc.kneighbors(return_distance=False)\n",
    "    \n",
    "    #Compute the intersection between true and embedding\n",
    "    for i in range(C):\n",
    "        intersections_knc += len(set(set_true_knc[i]) & set(set_embed_knc[i]))\n",
    "    KNC = intersections_knc / (C * knn_classes)\n",
    "    \n",
    "    ## CPD ##\n",
    "    #Pick a subset of pairwise points\n",
    "    subset = np.random.choice(X.shape[0], size=subsetsize, replace=False)\n",
    "    distance_true = pdist(X[subset,:])\n",
    "    distance_embed = pdist(Z[subset,:])\n",
    "    CPD = scipy.stats.spearmanr(distance_true[:,None],\n",
    "            distance_embed[:,None]).correlation\n",
    "    \n",
    "    return KNN, KNC, CPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load MNIST Fashion\n",
    "fashion = fetch_openml('Fashion-MNIST', version=1)\n",
    "X = fashion.data\n",
    "y = fashion.target.astype('int')\n",
    "#PCA\n",
    "X_whitened = X - X.mean(axis=0)\n",
    "U, s, V = np.linalg.svd(X_whitened, full_matrices=False)\n",
    "X784 = np.dot(U, np.diag(s))[:,:784]\n",
    "n = X784.shape[0]n = X784.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "id": "UR_yv2QGBqIi",
    "outputId": "b519f5d8-21e4-436a-a143-41083468a0fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed =[]\n",
    "# Methods\n",
    "#PCA - 2 components\n",
    "%time embed.append(PCA(n_components=2).fit_transform(X))\n",
    "#t-SNE random initialization\n",
    "%time embed.append(OpenTSNE(n_jobs=-1, random_state=42,\n",
    "        initialization='random',negative_gradient_method=\"bh\").fit(X784))\n",
    "#t-SNE PCA initialization\n",
    "%time embed.append(OpenTSNE(n_jobs=-1, random_state=42,\n",
    "        negative_gradient_method=\"bh\").fit(X784))\n",
    "#Multi-Scale kernel\n",
    "%time affinities_multiscale_mix = affinity.Multiscale(X784, \n",
    "        perplexities=[30, int(X784.shape[0]/100)], n_jobs=-1, random_state=42)\n",
    "%time pca_init = initialization.pca(X, \n",
    "        random_state=42)\n",
    "%time embedding0 = TSNEEmbedding(pca_init,affinities_multiscale_mix,\n",
    "        negative_gradient_method=\"bh\",n_jobs=8,random_state=42)\n",
    "%time embedding1 = embedding0.optimize(n_iter=250, exaggeration=12,\n",
    "        momentum=0.5,random_state=42)\n",
    "%time embed.append(embedding1.optimize(n_iter=750, exaggeration=1, \n",
    "        momentum=0.5, random_state=42))\n",
    "#Learning Rate adjusted\n",
    "%time affinities_multiscale_mix = affinity.Multiscale(X784, \n",
    "        perplexities=[30, int(X784.shape[0]/100)], n_jobs=-1, random_state=42)\n",
    "%time pca_init = initialization.pca(X, random_state=42)\n",
    "%time embedding0 = TSNEEmbedding(pca_init,affinities_multiscale_mix,n/12,\n",
    "        negative_gradient_method=\"bh\",n_jobs=8,random_state=42)\n",
    "%time embedding1 = embedding0.optimize(n_iter=250, exaggeration=12, \n",
    "        momentum=0.5,random_state=42)\n",
    "%time embed.append(embedding1.optimize(n_iter=750, exaggeration=1, \n",
    "        momentum=0.5,random_state=42))\n",
    "#UMAP random initialization\n",
    "%time embed.append(UMAP(random_state=42, init='random').fit_transform(X))\n",
    "#UMAP LE initialization\n",
    "%time embed.append(UMAP(random_state=42).fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Irk3gLEmCzHy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Calculate KNN, KNC, and CPD\n",
    "metrics = []\n",
    "for i in range(len(embed)):\n",
    "    knn, knc, cpd = embedding_metrics(X, embed[i], y, knn=10, knn_classes=4, subsetsize=1000)\n",
    "    metrics.append((knn, knc, cpd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titles = [\"PCA\", \"(Fi)t-SNE with PCA initialization\\n(Learning rate $\\eta=200$ Perplexity 30)\", \n",
    "          \"(Fi)t-SNE with PCA initialization\\n(Multiscale Similarities 30, n/100)\",\n",
    "          \"(Fi)t-SNE with PCA initialization\\n(Learning rate $\\eta=n/12$\\nMultiscale Similarities 30, n/100)\", \"UMAP with Random Initialization\",\n",
    "          \"UMAP with Laplacian Eigenmaps\"]\n",
    "\n",
    "letters = 'abcdefgh'\n",
    "\n",
    "plt.figure(figsize=(7.2, 4.5))\n",
    "\n",
    "# Add plots \n",
    "for i,Z in enumerate(embed):\n",
    "    plt.subplot(2,3,1+i)\n",
    "    plt.gca().set_aspect('equal', adjustable='datalim')\n",
    "    rand_order = np.random.permutation(Z.shape[0])\n",
    "    plt.scatter(Z[rand_order,0], Z[rand_order,1], s=1, c=y[rand_order], cmap='rainbow', \n",
    "                rasterized=True, edgecolor='none')\n",
    "    plt.title(titles[i], va='center')\n",
    "    plt.text(0.69,.02,'KNN:\\nKNC:\\nCPD:', transform=plt.gca().transAxes, fontsize=6)\n",
    "    plt.text(0.90,.02,'{:.2f}\\n{:.2f}\\n{:.2f}'.format(\n",
    "        metrics[i][0], metrics[i][1], metrics[i][2]), transform=plt.gca().transAxes, fontsize=6)\n",
    "    plt.text(0, 0, letters[i], transform = plt.gca().transAxes, fontsize=8, fontweight='bold')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('clustering/mnist-fash-simulation.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Prepare data to cluster\n",
    "embeddings_to_cluster = [X]\n",
    "for Z in embed:\n",
    "    embeddings_to_cluster.append(Z)\n",
    "\n",
    "clustering_labels = []\n",
    "clustered_labels = []\n",
    "rand_score_clustered = []\n",
    "mi_score_clustered = []\n",
    "rand_score = []\n",
    "mi_score = []\n",
    "total_capture = []\n",
    "\n",
    "#Cluster based on all embeddings including the raw data\n",
    "for i in range(len(embeddings_to_cluster)):\n",
    "    if i == 0:\n",
    "        clustering_labels.append(hdbscan.HDBSCAN(min_samples=10,\n",
    "            min_cluster_size=500).fit_predict(X784))\n",
    "    else:\n",
    "        clustering_labels.append(hdbscan.HDBSCAN(min_samples=10,\n",
    "            min_cluster_size=500).fit_predict(embeddings_to_cluster[i]))\n",
    "    clustered = (clustering_labels[i] >= 0)\n",
    "    clustered_labels.append(clustered)\n",
    "    #Total Score\n",
    "    rand_score.append(adjusted_rand_score(y, clustering_labels[i]))\n",
    "    mi_score.append(adjusted_mutual_info_score(y, clustering_labels[i]))\n",
    "    #Scores based on what was actually clustered\n",
    "    rand_score_clustered.append(adjusted_rand_score(y[clustered],\n",
    "                                     clustering_labels[i][clustered]))\n",
    "    mi_score_clustered.append(adjusted_mutual_info_score(y[clustered], \n",
    "                                     clustering_labels[i][clustered]))\n",
    "    #Total capture\n",
    "    total_capture.append(np.sum(clustered) / X.shape[0])\n",
    "\n",
    "#Add best KNN/KNC/CPD trade off embedding as benchmark for HDBSCAN\n",
    "embed_for_cluster = [embed[1]]\n",
    "for Z in embed:\n",
    "    embed_for_cluster.append(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titles = [\"HDBSCAN\", \"PCA\", \"(Fi)t-SNE with PCA initialization\\n(Learning rate $\\eta=200$ Perplexity 30)\", \n",
    "          \"(Fi)t-SNE with PCA initialization\\n(Multiscale Similarities 30, n/100)\",\n",
    "          \"(Fi)t-SNE with PCA initialization\\n(Learning rate $\\eta=n/12$\\nMultiscale Similarities 30, n/100)\", \"UMAP with Random Initialization\",\n",
    "          \"UMAP with Laplacian Eigenmaps\"]\n",
    "\n",
    "letters = 'abcdefgh'\n",
    "\n",
    "plt.figure(figsize=(7.2, 4.5))\n",
    "\n",
    "#Plot clustering on top of the embedding\n",
    "for i,Z in enumerate(embed_for_cluster):\n",
    "    plt.subplot(2,4,1+i)\n",
    "    plt.gca().set_aspect('equal', adjustable='datalim')\n",
    "    #PLot clustering on top of the non-clustered data\n",
    "    plt.scatter(Z[~clustered_labels[i],0], Z[~clustered_labels[i],1], \n",
    "                s=1, color=(.5,.5,.5), alpha=0.5,\n",
    "                rasterized=True, edgecolor='none') #not clustered\n",
    "    plt.scatter(Z[clustered_labels[i],0], Z[clustered_labels[i],1], s=1, \n",
    "                c=clustering_labels[i][clustered_labels[i]], cmap='rainbow', \n",
    "                rasterized=True, edgecolor='none') #clustered\n",
    "    plt.title(titles[i], va='center')\n",
    "    #Add clustering scores\n",
    "    plt.text(0.69,.02,'MIC:\\nARIC:\\nMI:\\nARI:', transform=plt.gca().transAxes, fontsize=6)\n",
    "    plt.text(0.90,.02,'{:.2f}\\n{:.2f}\\n{:.2f}\\n{:.2f}'.format( \n",
    "        mi_score_clustered[i], rand_score_clustered[i], mi_score[i], rand_score[i]),\n",
    "        transform=plt.gca().transAxes, fontsize=6)\n",
    "    #Add capture %\n",
    "    plt.text(0.1,0.9, 'C%:', transform = plt.gca().transAxes, fontsize=8, fontweight='bold')\n",
    "    plt.text(0.28,0.9, '{:.2f}'.format(total_capture[i]*100), transform = plt.gca().transAxes, fontsize=8, fontweight='bold')\n",
    "    plt.text(0, 0, letters[i], transform = plt.gca().transAxes, fontsize=8, fontweight='bold')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('clustering/report/cluster_fash.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "tsne.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
